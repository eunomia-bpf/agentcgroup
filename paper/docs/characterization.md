# 3 Characterization

我们对生产级 AI coding agent 的资源使用模式进行了首次系统性测量研究，分析了 SWE-rebench 数据集中 18 个任务在两个不同 agent 实现上的执行情况。通过每秒采样 CPU 和内存使用，以及记录完整的工具调用 trace，我们揭示了 AI agent 工作负载的独特资源特征。

## 3.1 Experimental Setup

**数据集。** 我们从 SWE-rebench 数据集中选取 18 个任务，覆盖六个类别（CLI_Tools、DevOps_Build、ML_Scientific、Medical_Bio、SQL_Data、Web_Network）和三个难度级别（Easy、Medium、Hard）。这些任务涵盖了 AI coding agent 的典型使用场景，包括命令行工具修复、构建系统配置、机器学习代码调试、生物医学数据处理、数据库查询优化和 Web 服务修复。

**Agent 实现。** 我们使用两个不同的 agent 实现执行相同的 18 个任务：Claude Code with Haiku（Anthropic 的生产级 AI coding agent）和基于 Qwen 模型的本地 agent 实现。选择这两个 agent 是为了观察不同架构和推理策略对资源使用的影响。

**数据收集。** 对于每个任务执行，我们以 1 秒间隔采样 CPU 利用率和内存使用量，并记录每个工具调用的类型、开始时间和结束时间。所有任务在相同的沙箱环境中执行，以确保测量的可比性。

## 3.2 Resource Dynamics

Agent 工作负载的资源使用呈现剧烈的时间波动特征。图 1 展示了一个典型 ML 任务执行过程中的资源使用时序。可以观察到，内存使用在单个采样间隔（1 秒）内变化高达 2.9GB，CPU 利用率出现剧烈波动，峰值超过 100%（多核利用）。资源使用呈现明显的"突发"模式，而非平稳变化。

![图 1：ML 任务中的资源使用时序图。内存在单秒间隔内变化高达 2.9GB。](../figures/fig1_timeseries.png)

图 2 展示了所有 18 个任务中资源变化率的分布。我们观察到最大内存变化率达到 3GB/秒，最大 CPU 变化率超过 50%/秒。显著变化事件（CPU 变化超过 20% 或内存变化超过 50MB/秒）占所有采样点的 1.6%–4.1%。这些数据表明，agent 工作负载产生短暂、突发的资源需求，变化发生在秒级甚至更快的时间尺度上。

![图 2：资源变化率分布。显著变化发生在 1 秒间隔内。](../figures/fig2_change_rate.png)

## 3.3 Resource Heterogeneity

不同任务和不同 agent 之间的资源需求存在显著差异。图 3 展示了不同任务类别的资源需求分布。峰值内存需求范围从 197MB 到 4GB，变异系数（CV）达到 147%。ML_Scientific 和 Medical_Bio 类别的任务表现出显著高于 CLI_Tools 或 Web_Network 任务的内存需求，但所有任务都在同一个容器中运行。

![图 3：不同任务类别的资源需求。变异系数达到 147%。](../figures/fig3_categories.png)

图 4 对比了 Haiku 和 Qwen agent 在相同 18 个任务上的 CPU 利用率。同样的任务在两个 agent 上表现出 3.9 倍的 CPU 利用率差异（Haiku 平均 30.6%，Qwen 平均 7.9%）。这一结果表明，资源需求不仅取决于任务本身，还取决于 agent 的架构和实现。不同的推理策略、工具调用模式和执行效率导致了截然不同的资源配置。

![图 4：不同 Agent 的 CPU 利用率对比。差异达到 3.9 倍。](../figures/fig4_cpu_diff.png)

## 3.4 Provisioning Efficiency

静态资源分配在 agent 工作负载上表现出严重的效率问题。图 5 展示了按峰值需求设置静态资源限制时的利用率情况。如果将 CPU 限制设置为峰值需求，Haiku 数据集的实际利用率仅为 24%，浪费 76%；Qwen 数据集的实际利用率仅为 7%，浪费 93%。过度供给因子在 CPU 上为 4.1×–13.6×，在内存上为 1.6×–2.4×。

![图 5：静态资源限制的过度供给分析。浪费率达到 76%–93%。](../figures/fig5_overprovisioning.png)

静态预算无论如何设置都会产生问题：保守设置（按峰值）导致 76%–93% 的资源浪费；激进设置（按平均）在突发期间导致 OOM 或性能下降。

## 3.5 Summary and Implications

基于以上观察，我们识别出现有资源管理工具在处理 AI agent 工作负载时的两个根本性问题。

**时间尺度不匹配。** 用户空间资源控制器的典型工作流程是监控资源压力指标（如 PSI、memory.events），做出调整决策，然后写入 cgroup 控制文件。这个循环通常需要 10–100ms。然而，我们的测量表明 agent 工作负载的资源变化发生在秒级甚至更快的时间尺度上。当用户空间控制器观察到内存压力并调整限制时，突发已经导致了 reclaim 风暴或运行队列膨胀。任何基于用户空间监控和 cgroup 文件写入的方法都无法及时响应 agent 工作负载的资源突发。

**域不匹配。** 现有资源控制在容器粒度设置静态预算（如 Kubernetes resource limits、Docker --memory/--cpus、systemd ResourceControl），但 agent 工作负载需要工具调用级别的动态控制。我们的测量表明，不同任务的资源需求变异系数高达 147%，不同 agent 的 CPU 利用率差异达 3.9 倍，静态限制导致 76%–93% 的资源浪费。静态资源限制无法适应 agent 工作负载的动态、多相位特性。

此外，现有工具缺乏表达相位感知控制（根据执行阶段调整资源）、工具类型感知控制（根据工具类型分配资源）和跨资源协调（CPU 与内存策略联动）的能力。

这些差距共同表明：有效的 agent 资源管理需要内核级执行（控制逻辑在内核执行点实现微秒级响应）和动态细粒度控制（资源域与工具调用边界对齐）。这正是 AgentCgroup 的设计动机。
